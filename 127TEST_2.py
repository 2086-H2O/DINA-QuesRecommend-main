"""
åŠé®é¢å®éªŒï¼Œæˆ‘ä»¬æ˜¯é€‰ç”¨ræ¯”ä¾‹çš„äººæ¥è®¡ç®—æ‰€æœ‰é¢˜ç›®çš„sgï¼Œ1-ræ¯”ä¾‹çš„äººæ¥å½“å¿—æ„¿è€…ï¼Œå–ä»–ä»¬kæ¯”ä¾‹çš„ç­”é¢˜å¡æ¥è¿›è¡Œèƒ½åŠ›åˆ»ç”»ï¼Œ1-kæ¯”ä¾‹æ¥æµ‹è¯•åˆ»ç”»æ˜¯å¦æˆåŠŸã€‚
"""
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, log_loss
from itertools import product
import os
import warnings

# å¿½ç•¥æ•°å€¼è®¡ç®—ä¸­çš„ä¸€äº›é™¤é›¶è­¦å‘Š
warnings.filterwarnings('ignore')

# ==========================================
#               1. å®éªŒé…ç½®åŒº (User Config)
# ==========================================

# --- æ ¸å¿ƒå‚æ•°é…ç½® ---
R_TRAIN_STUDENTS = 0.7  # r: 80% çš„å­¦ç”Ÿç”¨äºè®­ç»ƒé¢˜ç›®å‚æ•° (s, g)
K_OBSERVED_ITEMS = 0.5  # k: æµ‹è¯•é›†å­¦ç”Ÿ 50% çš„é¢˜ç›®å·²çŸ¥ï¼Œç”¨äºé¢„æµ‹å‰©ä¸‹ 50%
RANDOM_SEED = 42        # å›ºå®šéšæœºç§å­
MAX_KNOWLEDGE = 15      # æ™ºèƒ½é™ç»´é˜ˆå€¼ (é˜²æ­¢ 516matrix æ­»æœº)

# --- å¾…æµ‹ Q çŸ©é˜µåˆ—è¡¨ ---
# æ³¨æ„ï¼šè¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œæˆ‘å·²æ ¹æ®ä½ çš„æ–‡ä»¶ç»“æ„åšäº†é¢„è®¾
Q_MATRIX_LIST = {
    "1. LLMç­–ç•¥2": r"LLM_Q_Generate\outputs\4+10_1_æ”¹_results\DINA_Q_Matrix_4+10_æ”¹.xlsx",
    "2. LLMç­–ç•¥3": r"LLM_Q_Generate\outputs\4+10_2_8_results\DINA_Q_Matrix_4+10_2_8.xlsx",
    "3. LLMç­–ç•¥4": r"LLM_Q_Generate\outputs\4+10_3_results\DINA_Q_Matrix_3.xlsx",
    "4. ä¸“å®¶æ‰‹å·¥é™ç»´ (14ç»´)": r"Artificial_Q_process\QçŸ©é˜µ_æ‰‹å·¥æ ‡æ³¨åˆå¹¶14ä¸ª.xlsx",
    "5. è€ç‰ˆæœ¬ V1 (10ç»´-è¯é¢‘)": r"516matrix.xlsx"
}

DATA_PATH = "cleaned_data_20250326_0931.csv"
GROUP_PATH = "optimal_student_groups_leiden.csv"
# å…¼å®¹è·¯å¾„å‰ç¼€ï¼ˆå¦‚æœè„šæœ¬åœ¨æ ¹ç›®å½•è¿è¡Œï¼‰
if not os.path.exists(DATA_PATH) and os.path.exists(f"DINA-QuesRecommend-main/{DATA_PATH}"):
    DATA_PATH = f"DINA-QuesRecommend-main/{DATA_PATH}"
if not os.path.exists(GROUP_PATH) and os.path.exists(f"DINA-QuesRecommend-main/{GROUP_PATH}"):
    GROUP_PATH = f"DINA-QuesRecommend-main/{GROUP_PATH}"

# ==========================================
#           2. DINA æ ¸å¿ƒç®—å­
# ==========================================

def compute_eta(Q, A):
    kowns = np.sum(Q * Q, axis=0)
    cross = np.dot(A, Q)
    eta = np.ones(shape=(A.shape[0], Q.shape[1]))
    eta[cross < kowns] = 0
    return eta

def compute_propa(eta, s, g):
    propa = (g ** (1 - eta)) * ((1 - s) ** eta)
    return np.clip(propa, 1e-10, 1 - 1e-10)

def compute_gamma(X, pi, propa):
    log_pj = np.log(propa)
    log_qj = np.log(1 - propa)
    log_pi = np.log(pi)
    gamma = np.exp(np.dot(X, log_pj.T) + np.dot((1 - X), log_qj.T) + log_pi)
    gamma_sum = np.sum(gamma, axis=1, keepdims=True)
    gamma_sum[gamma_sum == 0] = 1e-15
    return gamma / gamma_sum

def compute_theta(X, gamma, eta):
    I0 = np.dot(gamma, 1 - eta)
    I1 = np.dot(gamma, eta)
    R0 = I0 * X
    R1 = I1 * X
    
    I0_sum, I1_sum = np.sum(I0, axis=0), np.sum(I1, axis=0)
    R0_sum, R1_sum = np.sum(R0, axis=0), np.sum(R1, axis=0)
    
    I0_sum[I0_sum <= 0] = 1e-15
    I1_sum[I1_sum <= 0] = 1e-15
    
    g = R0_sum / I0_sum
    s = (I1_sum - R1_sum) / I1_sum
    pi = np.sum(gamma, axis=0) / gamma.shape[0]
    
    return np.clip(pi, 1e-15, 1-1e-15), np.clip(s, 0.001, 0.999), np.clip(g, 0.001, 0.999)

def train_dina(X, Q, max_iter=30, tol=1e-3):
    """å…¨é‡è®­ç»ƒæ¨¡å¼ï¼šå­¦ä¹  s, g"""
    n_items = X.shape[1]
    n_kno = Q.shape[0]
    
    s = np.random.uniform(0.1, 0.3, n_items)
    g = np.random.uniform(0.1, 0.3, n_items)
    A_all = np.array(list(product([0, 1], repeat=n_kno)))
    pi = np.ones(A_all.shape[0]) / A_all.shape[0]
    
    for t in range(max_iter):
        eta = compute_eta(Q, A_all)
        propa = compute_propa(eta, s, g)
        gamma = compute_gamma(X, pi, propa)
        pi_new, s_new, g_new = compute_theta(X, gamma, eta)
        
        diff = max(np.max(np.abs(pi_new - pi)), np.max(np.abs(s_new - s)), np.max(np.abs(g_new - g)))
        pi, s, g = pi_new, s_new, g_new
        if diff < tol: break
            
    return {"s": s, "g": g, "pi": pi, "A_all": A_all}

# ==========================================
#      3. æ™ºèƒ½ Q çŸ©é˜µæ„å»º (è‡ªåŠ¨é˜²çˆ†)
# ==========================================

def build_smart_q_matrix(file_path, group_qs_ids, max_k=15):
    try:
        # å…¼å®¹è·¯å¾„ï¼šå°è¯•åœ¨å½“å‰ç›®å½•æ‰¾ï¼Œæˆ–è€…åŠ ä¸Š DINA-QuesRecommend-main å‰ç¼€
        if not os.path.exists(file_path):
            alt_path = f"DINA-QuesRecommend-main/{file_path}"
            if os.path.exists(alt_path):
                file_path = alt_path
            else:
                # å°è¯•åªç”¨æ–‡ä»¶å
                base_name = os.path.basename(file_path)
                # é€’å½’æŸ¥æ‰¾
                for root, dirs, files in os.walk("."):
                    if base_name in files:
                        file_path = os.path.join(root, base_name)
                        break
        
        if not os.path.exists(file_path):
            print(f"   [Error] æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
            return None, None

        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path)
            
        # ç´¢å¼•å¤„ç†
        cols_lower = [c.lower() for c in df.columns]
        if 'id' in cols_lower: df = df.set_index(df.columns[cols_lower.index('id')])
        elif 'qs_id' in cols_lower: df = df.set_index(df.columns[cols_lower.index('qs_id')])
        else: df = df.set_index(df.columns[0])
        df.index = df.index.astype(str)
        
        # æå–çŸ¥è¯†ç‚¹åˆ— (æ•°å€¼åˆ—)
        numeric_df = df.select_dtypes(include=[np.number]).fillna(0)
        
        valid_qs = [q for q in group_qs_ids if q in df.index]
        if not valid_qs: return None, None
        
        subset_df = numeric_df.loc[valid_qs]
        
        # æ™ºèƒ½é™ç»´
        if subset_df.shape[1] > max_k:
            print(f"   [ä¼˜åŒ–] çŸ¥è¯†ç‚¹ {subset_df.shape[1]} > {max_k}ï¼Œæ‰§è¡Œ Top-K é™ç»´...")
            top_cols = subset_df.sum(axis=0).nlargest(max_k).index
            subset_df = subset_df[top_cols]
            
        Q = (subset_df.values > 0).astype(int).T
        
        # ç§»é™¤å…¨é›¶è¡Œ
        valid_k = np.where(Q.sum(axis=1) > 0)[0]
        Q = Q[valid_k, :]
        
        return Q, valid_qs
    except Exception as e:
        print(f"   [Load Error] {e}")
        return None, None

# ==========================================
#               4. å®éªŒä¸»ç¨‹åº
# ==========================================

def run_experiment():
    print(f"ğŸš€ å¼€å§‹åŠé®é¢å®éªŒ | è®­ç»ƒå­¦ç”Ÿr={R_TRAIN_STUDENTS} | å·²çŸ¥é¢˜ç›®k={K_OBSERVED_ITEMS}")
    print("=" * 70)
    
    # åŠ è½½åŸºç¡€æ•°æ®
    try:
        data = pd.read_csv(DATA_PATH)
        data['qs_id'] = data['qs_id'].astype(str)
        groups = pd.read_csv(GROUP_PATH)
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    results = []

    for q_name, q_path in Q_MATRIX_LIST.items():
        print(f"\nğŸ“‚ æ­£åœ¨è¯„æµ‹: [{q_name}]")
        print("-" * 50)
        
        # éå†æ‰€æœ‰ç»„
        for grp_id in [0, 1, 2]:
            # 1. å‡†å¤‡è¯¥ç»„æ•°æ®
            stu_ids = groups[groups['group'] == grp_id]['student_id'].values
            if len(stu_ids) < 10: continue
            
            X_df = data[data['student_id'].isin(stu_ids)].pivot_table(
                index='student_id', columns='qs_id', values='qs_validity', fill_value=0
            )
            
            # 2. æ„å»º Q çŸ©é˜µ
            Q, valid_qs = build_smart_q_matrix(q_path, X_df.columns.astype(str).tolist(), MAX_KNOWLEDGE)
            if Q is None: continue
            
            X = X_df[valid_qs].values
            n_items = X.shape[1]
            n_kno = Q.shape[0]
            
            # 3. åˆ’åˆ†å­¦ç”Ÿ (Train / Test Split)
            # r æ¯”ä¾‹çš„å­¦ç”Ÿç”¨äºå­¦ä¹ é¢˜ç›®å±æ€§
            X_train_stu, X_test_stu = train_test_split(X, train_size=R_TRAIN_STUDENTS, random_state=RANDOM_SEED)
            
            # --- Phase 1: è®­ç»ƒé¢˜ç›®å±æ€§ (s, g) ---
            # print(f"   Group {grp_id}: è®­ç»ƒé¢˜ç›®å‚æ•° (N={len(X_train_stu)})...")
            model = train_dina(X_train_stu, Q, max_iter=30)
            s_learned, g_learned, pi_learned = model['s'], model['g'], model['pi']
            A_all = model['A_all']
            
            # --- Phase 2: æµ‹è¯•é›†åŠé®é¢é¢„æµ‹ ---
            # å¯¹æµ‹è¯•é›†ä¸­çš„æ¯ä¸ªå­¦ç”Ÿï¼Œéšæœºé®æŒ¡ 1-k æ¯”ä¾‹çš„é¢˜ç›®
            # ä¸ºäº†ç®€åŒ–è®¡ç®—ä¸”ä¿è¯ç»Ÿè®¡æ„ä¹‰ï¼Œæˆ‘ä»¬å¯¹é¢˜ç›®è¿›è¡Œä¸€æ¬¡æ€§éšæœºåˆ‡åˆ†
            # (ä¹Ÿå¯ä»¥å¯¹æ¯ä¸ªå­¦ç”Ÿå•ç‹¬åˆ‡åˆ†ï¼Œä½†è®¡ç®—é‡ä¼šå¤§å¢ï¼Œè¿™é‡Œé‡‡ç”¨ç»Ÿä¸€æ©ç )
            
            all_indices = np.arange(n_items)
            np.random.shuffle(all_indices)
            n_obs = int(n_items * K_OBSERVED_ITEMS)
            
            idx_obs = all_indices[:n_obs] # å·²çŸ¥ (ç”¨æ¥æ¨æ–­èƒ½åŠ›)
            idx_tar = all_indices[n_obs:] # é®æŒ¡ (ç”¨æ¥éªŒè¯é¢„æµ‹)
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            X_obs = X_test_stu[:, idx_obs]
            X_tar = X_test_stu[:, idx_tar]
            
            Q_obs = Q[:, idx_obs]
            s_obs, g_obs = s_learned[idx_obs], g_learned[idx_obs]
            
            Q_tar = Q[:, idx_tar]
            s_tar, g_tar = s_learned[idx_tar], g_learned[idx_tar]
            
            # Step A: æ¨æ–­èƒ½åŠ› (Inference)
            # ä»…ä½¿ç”¨ Observed é¢˜ç›® + è®­ç»ƒå¥½çš„å‚æ•°
            eta_obs = compute_eta(Q_obs, A_all)
            propa_obs = compute_propa(eta_obs, s_obs, g_obs)
            gamma_test = compute_gamma(X_obs, pi_learned, propa_obs)
            
            # Step B: é¢„æµ‹é®æŒ¡é¢˜ç›® (Prediction)
            eta_tar = compute_eta(Q_tar, A_all)
            propa_tar = compute_propa(eta_tar, s_tar, g_tar)
            
            # é¢„æµ‹æ¦‚ç‡ = Gamma * Propa_Target
            X_pred_prob = np.dot(gamma_test, propa_tar)
            X_pred_bin = (X_pred_prob >= 0.5).astype(int)
            
            # Step C: è®¡ç®—æŒ‡æ ‡
            acc = accuracy_score(X_tar.flatten(), X_pred_bin.flatten())
            loss = log_loss(X_tar.flatten(), X_pred_prob.flatten(), labels=[0,1])
            
            print(f"   Group {grp_id} (K={n_kno}): Acc = {acc:.4f} | Loss = {loss:.4f} | (Test N={len(X_test_stu)})")
            
            results.append({
                "Matrix": q_name,
                "Group": grp_id,
                "Knowledge_Dim": n_kno,
                "Test_Students": len(X_test_stu),
                "Split_Accuracy": acc,
                "Split_LogLoss": loss
            })

    # æ±‡æ€»è¾“å‡º
    print("\n" + "="*70)
    print("ğŸ† åŠé®é¢å®éªŒç»“æœæ±‡æ€» (æŒ‰ Accuracy æ’åº)")
    print("="*70)
    if results:
        res_df = pd.DataFrame(results)
        res_df = res_df[["Matrix", "Group", "Knowledge_Dim", "Split_Accuracy", "Split_LogLoss"]]
        print(res_df.sort_values(by="Split_Accuracy", ascending=False).to_string(index=False))
        res_df.to_csv("split_item_experiment_results.csv", index=False)
    else:
        print("æ— æœ‰æ•ˆç»“æœ")

if __name__ == "__main__":
    run_experiment()
"""
å…¨é‡å­¦ç”Ÿã€å…¨é‡é¢˜ç›®çš„è‡ªæ´½æ€§æ£€éªŒï¼Œä¸åˆ†ç»„
"""
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, log_loss
from itertools import product
import os
import warnings

# å¿½ç•¥æ•°å€¼è®¡ç®—è­¦å‘Š
warnings.filterwarnings('ignore')

# ================= é…ç½®åŒº =================
# å®éªŒåç§°
EXPERIMENT_NAME = "å…¨é‡æ•°æ®è‡ªæ´½æ€§æ£€éªŒ (Self-Consistency Check)"
MAX_KNOWLEDGE = 15      # æ™ºèƒ½é™ç»´é˜ˆå€¼

# å¾…æµ‹ Q çŸ©é˜µåˆ—è¡¨
Q_MATRIX_LIST = {
    "1. LLMç­–ç•¥2": r"LLM_Q_Generate\outputs\4+10_1_æ”¹_results\DINA_Q_Matrix_4+10_æ”¹.xlsx",
    "2. LLMç­–ç•¥3": r"LLM_Q_Generate\outputs\4+10_2_8_results\DINA_Q_Matrix_4+10_2_8.xlsx",
    "3. LLMç­–ç•¥4": r"LLM_Q_Generate\outputs\4+10_3_results\DINA_Q_Matrix_3.xlsx",
    "4. ä¸“å®¶æ‰‹å·¥é™ç»´ (14ç»´)": r"Artificial_Q_process\QçŸ©é˜µ_æ‰‹å·¥æ ‡æ³¨åˆå¹¶14ä¸ª.xlsx",
    "5. è€ç‰ˆæœ¬ V1 (10ç»´-è¯é¢‘)": r"516matrix.xlsx"
}

DATA_PATH = "cleaned_data_20250326_0931.csv"
if not os.path.exists(DATA_PATH) and os.path.exists(f"DINA-QuesRecommend-main/{DATA_PATH}"):
    DATA_PATH = f"DINA-QuesRecommend-main/{DATA_PATH}"

# ================= DINA æ ¸å¿ƒç®—å­ =================
def compute_eta(Q, A):
    kowns = np.sum(Q * Q, axis=0)
    cross = np.dot(A, Q)
    eta = np.ones(shape=(A.shape[0], Q.shape[1]))
    eta[cross < kowns] = 0
    return eta

def compute_propa(eta, s, g):
    propa = (g ** (1 - eta)) * ((1 - s) ** eta)
    return np.clip(propa, 1e-10, 1 - 1e-10)

def compute_gamma(X, pi, propa):
    log_pj = np.log(propa)
    log_qj = np.log(1 - propa)
    log_pi = np.log(pi)
    gamma = np.exp(np.dot(X, log_pj.T) + np.dot((1 - X), log_qj.T) + log_pi)
    gamma_sum = np.sum(gamma, axis=1, keepdims=True)
    gamma_sum[gamma_sum == 0] = 1e-15
    return gamma / gamma_sum

def compute_theta(X, gamma, eta):
    I0 = np.dot(gamma, 1 - eta)
    I1 = np.dot(gamma, eta)
    R0 = I0 * X
    R1 = I1 * X
    
    g = np.sum(R0, axis=0) / np.maximum(np.sum(I0, axis=0), 1e-15)
    s = (np.sum(I1, axis=0) - np.sum(R1, axis=0)) / np.maximum(np.sum(I1, axis=0), 1e-15)
    pi = np.sum(gamma, axis=0) / gamma.shape[0]
    
    return np.clip(pi, 1e-15, 1-1e-15), np.clip(s, 0.001, 0.999), np.clip(g, 0.001, 0.999)

def train_dina_full(X, Q, max_iter=200, tol=1e-3):
    """å…¨é‡è®­ç»ƒï¼Œè¿”å›æœ€ç»ˆçš„æ‹Ÿåˆå‚æ•°"""
    n_items = X.shape[1]
    n_kno = Q.shape[0]
    
    # åˆå§‹åŒ–
    s = np.random.uniform(0.1, 0.3, n_items)
    g = np.random.uniform(0.1, 0.3, n_items)
    A_all = np.array(list(product([0, 1], repeat=n_kno)))
    pi = np.ones(A_all.shape[0]) / A_all.shape[0]
    
    for t in range(max_iter):
        eta = compute_eta(Q, A_all)
        propa = compute_propa(eta, s, g)
        gamma = compute_gamma(X, pi, propa)
        pi_new, s_new, g_new = compute_theta(X, gamma, eta)
        
        diff = max(np.max(np.abs(pi_new - pi)), np.max(np.abs(s_new - s)), np.max(np.abs(g_new - g)))
        pi, s, g = pi_new, s_new, g_new
        if diff < tol: break
            
    # è®¡ç®—é‡æ„çŸ©é˜µ (Self-Consistency Check)
    # ç”¨æœ€ç»ˆå‚æ•°ç”Ÿæˆæ¯ä¸ªå­¦ç”Ÿçš„â€œç†è®ºç­”é¢˜æ¦‚ç‡â€
    # P(X_ij=1) = Sum_over_k ( Gamma_ik * P(X_ij=1|alpha_k) )
    eta_final = compute_eta(Q, A_all)
    propa_final = compute_propa(eta_final, s, g)
    X_reconstruct_prob = np.dot(gamma, propa_final)
    
    return X_reconstruct_prob, s, g

# ================= æ™ºèƒ½ Q çŸ©é˜µåŠ è½½ =================
def build_smart_q_matrix(file_path, group_qs_ids, max_k=15):
    try:
        # å…¼å®¹è·¯å¾„æŸ¥æ‰¾
        if not os.path.exists(file_path):
            alt_path = f"DINA-QuesRecommend-main/{file_path}"
            if os.path.exists(alt_path):
                file_path = alt_path
            else:
                base_name = os.path.basename(file_path)
                for root, dirs, files in os.walk("."):
                    if base_name in files:
                        file_path = os.path.join(root, base_name)
                        break
        
        if not os.path.exists(file_path):
            print(f"   [Error] æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
            return None, None

        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path)
            
        cols_lower = [c.lower() for c in df.columns]
        if 'id' in cols_lower: df = df.set_index(df.columns[cols_lower.index('id')])
        elif 'qs_id' in cols_lower: df = df.set_index(df.columns[cols_lower.index('qs_id')])
        else: df = df.set_index(df.columns[0])
        df.index = df.index.astype(str)
        
        numeric_df = df.select_dtypes(include=[np.number]).fillna(0)
        valid_qs = [q for q in group_qs_ids if q in df.index]
        
        if not valid_qs: return None, None
        
        subset_df = numeric_df.loc[valid_qs]
        if subset_df.shape[1] > max_k:
            print(f"   [ä¼˜åŒ–] çŸ¥è¯†ç‚¹ {subset_df.shape[1]} > {max_k}ï¼Œæ‰§è¡Œ Top-K é™ç»´...")
            top_cols = subset_df.sum(axis=0).nlargest(max_k).index
            subset_df = subset_df[top_cols]
            
        Q = (subset_df.values > 0).astype(int).T
        valid_k = np.where(Q.sum(axis=1) > 0)[0]
        Q = Q[valid_k, :]
        return Q, valid_qs
    except Exception as e:
        print(f"   [Load Error] {e}")
        return None, None

# ================= ä¸»ç¨‹åº =================
def run_consistency_check():
    print(f"ğŸš€ å¼€å§‹å…¨é‡è‡ªæ´½æ€§æ£€éªŒ (Training = 100% Data, Testing = 100% Data)")
    print("=" * 70)
    
    try:
        data = pd.read_csv(DATA_PATH)
        data['qs_id'] = data['qs_id'].astype(str)
        print("æ­£åœ¨æ„å»ºå…¨é‡ç­”é¢˜çŸ©é˜µ...")
        X_df = data.pivot_table(index='student_id', columns='qs_id', values='qs_validity', fill_value=0)
        print(f"âœ… å…¨é‡çŸ©é˜µ: {X_df.shape[0]} å­¦ç”Ÿ x {X_df.shape[1]} é¢˜ç›®")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    results = []

    for q_name, q_path in Q_MATRIX_LIST.items():
        print(f"\nğŸ“‚ æ­£åœ¨æ£€éªŒ: [{q_name}]")
        print("-" * 50)
        
        Q, valid_qs = build_smart_q_matrix(q_path, X_df.columns.astype(str).tolist(), MAX_KNOWLEDGE)
        if Q is None: continue
        
        X = X_df[valid_qs].values
        n_items = X.shape[1]
        n_kno = Q.shape[0]
        
        # æ ¸å¿ƒï¼šå…¨é‡è®­ç»ƒ + å…¨é‡å›æµ‹
        print(f"   æ‰§è¡Œ EM ç®—æ³• (N={len(X)})...")
        X_recon_prob, s, g = train_dina_full(X, Q, max_iter=30)
        
        # è¯„ä¼° (Compare Original vs Reconstructed)
        X_recon_bin = (X_recon_prob >= 0.5).astype(int)
        
        acc = accuracy_score(X.flatten(), X_recon_bin.flatten())
        loss = log_loss(X.flatten(), X_recon_prob.flatten(), labels=[0,1])
        
        # ç»Ÿè®¡å¹³å‡ s å’Œ g (åæ˜ é¢˜ç›®è´¨é‡)
        avg_s = np.mean(s)
        avg_g = np.mean(g)
        
        print(f"   [Result] Acc = {acc:.4f} | Loss = {loss:.4f} | Avg Slip={avg_s:.3f}, Avg Guess={avg_g:.3f}")
        
        results.append({
            "Matrix": q_name,
            "Knowledge_Dim": n_kno,
            "Consistency_Acc": acc,
            "Consistency_LogLoss": loss,
            "Avg_Slip": avg_s,
            "Avg_Guess": avg_g
        })

    print("\n" + "="*70)
    print("ğŸ† è‡ªæ´½æ€§æ£€éªŒæŠ¥å‘Š (æ‹Ÿåˆåº¦æ’å)")
    print("="*70)
    if results:
        res_df = pd.DataFrame(results)
        print(res_df.sort_values(by="Consistency_Acc", ascending=False).to_string(index=False))
        res_df.to_csv("consistency_check_results.csv", index=False)
    else:
        print("æ— ç»“æœ")

if __name__ == "__main__":
    run_consistency_check()
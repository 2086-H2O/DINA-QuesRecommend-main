"""
ä¸åˆ†ç»„çš„åŠé®é¢
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, log_loss
from itertools import product
import os
import warnings

# å¿½ç•¥æ•°å€¼è®¡ç®—ä¸­çš„ä¸€äº›é™¤é›¶è­¦å‘Š
warnings.filterwarnings('ignore')

# ==========================================
#               1. å®éªŒé…ç½®åŒº (User Config)
# ==========================================

# --- æ ¸å¿ƒå‚æ•°é…ç½® ---
EXPERIMENT_NAME = "å…¨é‡æ•°æ®æµ‹è¯• (All Students)"
R_TRAIN_STUDENTS = 0.8  # r: 80% çš„å­¦ç”Ÿç”¨äºè®­ç»ƒé¢˜ç›®å‚æ•° (s, g)
K_OBSERVED_ITEMS = 0.5  # k: æµ‹è¯•é›†å­¦ç”Ÿ 50% çš„é¢˜ç›®å·²çŸ¥ï¼Œç”¨äºé¢„æµ‹å‰©ä¸‹ 50%
RANDOM_SEED = 42        # å›ºå®šéšæœºç§å­
MAX_KNOWLEDGE = 15      # æ™ºèƒ½é™ç»´é˜ˆå€¼

# --- å¾…æµ‹ Q çŸ©é˜µåˆ—è¡¨ ---
Q_MATRIX_LIST = {
    "1. LLMç­–ç•¥2": r"LLM_Q_Generate\outputs\4+10_1_æ”¹_results\DINA_Q_Matrix_4+10_æ”¹.xlsx",
    "2. LLMç­–ç•¥3": r"LLM_Q_Generate\outputs\4+10_2_8_results\DINA_Q_Matrix_4+10_2_8.xlsx",
    "3. LLMç­–ç•¥4": r"LLM_Q_Generate\outputs\4+10_3_results\DINA_Q_Matrix_3.xlsx",
    "4. ä¸“å®¶æ‰‹å·¥é™ç»´ (14ç»´)": r"Artificial_Q_process\QçŸ©é˜µ_æ‰‹å·¥æ ‡æ³¨åˆå¹¶14ä¸ª.xlsx",
    "5. è€ç‰ˆæœ¬ V1 (10ç»´-è¯é¢‘)": r"516matrix.xlsx"
}


DATA_PATH = "cleaned_data_20250326_0931.csv"
# æ³¨æ„ï¼šæˆ‘ä»¬ç°åœ¨ä¸å†ä¾èµ– optimal_student_groups_leiden.csv æ¥åˆ‡åˆ†ï¼Œè€Œæ˜¯ç›´æ¥è¯»å– data é‡Œçš„æ‰€æœ‰å­¦ç”Ÿ

# å…¼å®¹è·¯å¾„å‰ç¼€
if not os.path.exists(DATA_PATH) and os.path.exists(f"DINA-QuesRecommend-main/{DATA_PATH}"):
    DATA_PATH = f"DINA-QuesRecommend-main/{DATA_PATH}"

# ==========================================
#           2. DINA æ ¸å¿ƒç®—å­
# ==========================================

def compute_eta(Q, A):
    kowns = np.sum(Q * Q, axis=0)
    cross = np.dot(A, Q)
    eta = np.ones(shape=(A.shape[0], Q.shape[1]))
    eta[cross < kowns] = 0
    return eta

def compute_propa(eta, s, g):
    propa = (g ** (1 - eta)) * ((1 - s) ** eta)
    return np.clip(propa, 1e-10, 1 - 1e-10)

def compute_gamma(X, pi, propa):
    log_pj = np.log(propa)
    log_qj = np.log(1 - propa)
    log_pi = np.log(pi)
    gamma = np.exp(np.dot(X, log_pj.T) + np.dot((1 - X), log_qj.T) + log_pi)
    gamma_sum = np.sum(gamma, axis=1, keepdims=True)
    gamma_sum[gamma_sum == 0] = 1e-15
    return gamma / gamma_sum

def compute_theta(X, gamma, eta):
    I0 = np.dot(gamma, 1 - eta)
    I1 = np.dot(gamma, eta)
    R0 = I0 * X
    R1 = I1 * X
    
    I0_sum, I1_sum = np.sum(I0, axis=0), np.sum(I1, axis=0)
    R0_sum, R1_sum = np.sum(R0, axis=0), np.sum(R1, axis=0)
    
    I0_sum[I0_sum <= 0] = 1e-15
    I1_sum[I1_sum <= 0] = 1e-15
    
    g = R0_sum / I0_sum
    s = (I1_sum - R1_sum) / I1_sum
    pi = np.sum(gamma, axis=0) / gamma.shape[0]
    
    return np.clip(pi, 1e-15, 1-1e-15), np.clip(s, 0.001, 0.999), np.clip(g, 0.001, 0.999)

def train_dina(X, Q, max_iter=30, tol=1e-3):
    n_items = X.shape[1]
    n_kno = Q.shape[0]
    
    s = np.random.uniform(0.1, 0.3, n_items)
    g = np.random.uniform(0.1, 0.3, n_items)
    A_all = np.array(list(product([0, 1], repeat=n_kno)))
    pi = np.ones(A_all.shape[0]) / A_all.shape[0]
    
    for t in range(max_iter):
        eta = compute_eta(Q, A_all)
        propa = compute_propa(eta, s, g)
        gamma = compute_gamma(X, pi, propa)
        pi_new, s_new, g_new = compute_theta(X, gamma, eta)
        
        diff = max(np.max(np.abs(pi_new - pi)), np.max(np.abs(s_new - s)), np.max(np.abs(g_new - g)))
        pi, s, g = pi_new, s_new, g_new
        if diff < tol: break
            
    return {"s": s, "g": g, "pi": pi, "A_all": A_all}

# ==========================================
#      3. æ™ºèƒ½ Q çŸ©é˜µæ„å»º
# ==========================================

def build_smart_q_matrix(file_path, group_qs_ids, max_k=15):
    try:
        # å…¼å®¹è·¯å¾„æŸ¥æ‰¾
        if not os.path.exists(file_path):
            alt_path = f"DINA-QuesRecommend-main/{file_path}"
            if os.path.exists(alt_path):
                file_path = alt_path
            else:
                base_name = os.path.basename(file_path)
                for root, dirs, files in os.walk("."):
                    if base_name in files:
                        file_path = os.path.join(root, base_name)
                        break
        
        if not os.path.exists(file_path):
            print(f"   [Error] æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
            return None, None

        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        else:
            df = pd.read_excel(file_path)
            
        # ç´¢å¼•å¤„ç†
        cols_lower = [c.lower() for c in df.columns]
        if 'id' in cols_lower: df = df.set_index(df.columns[cols_lower.index('id')])
        elif 'qs_id' in cols_lower: df = df.set_index(df.columns[cols_lower.index('qs_id')])
        else: df = df.set_index(df.columns[0])
        df.index = df.index.astype(str)
        
        # æå–çŸ¥è¯†ç‚¹
        numeric_df = df.select_dtypes(include=[np.number]).fillna(0)
        
        valid_qs = [q for q in group_qs_ids if q in df.index]
        if not valid_qs: return None, None
        
        subset_df = numeric_df.loc[valid_qs]
        
        # æ™ºèƒ½é™ç»´
        if subset_df.shape[1] > max_k:
            print(f"   [ä¼˜åŒ–] çŸ¥è¯†ç‚¹ {subset_df.shape[1]} > {max_k}ï¼Œæ‰§è¡Œ Top-K é™ç»´...")
            top_cols = subset_df.sum(axis=0).nlargest(max_k).index
            subset_df = subset_df[top_cols]
            
        Q = (subset_df.values > 0).astype(int).T
        valid_k = np.where(Q.sum(axis=1) > 0)[0]
        Q = Q[valid_k, :]
        
        return Q, valid_qs
    except Exception as e:
        print(f"   [Load Error] {e}")
        return None, None

# ==========================================
#               4. å®éªŒä¸»ç¨‹åº
# ==========================================

def run_experiment():
    print(f"ğŸš€ å¼€å§‹å…¨é‡æ•°æ®æµ‹è¯• | è®­ç»ƒr={R_TRAIN_STUDENTS} | å·²çŸ¥k={K_OBSERVED_ITEMS}")
    print("=" * 70)
    
    # 1. åŠ è½½æ‰€æœ‰æ•°æ®
    try:
        data = pd.read_csv(DATA_PATH)
        data['qs_id'] = data['qs_id'].astype(str)
        
        # ç›´æ¥é€è§†æ‰€æœ‰å­¦ç”Ÿæ•°æ®ï¼Œä¸åˆ† Group
        print("æ­£åœ¨æ„å»ºå…¨é‡å­¦ç”Ÿç­”é¢˜çŸ©é˜µ (è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
        X_df = data.pivot_table(
            index='student_id', columns='qs_id', values='qs_validity', fill_value=0
        )
        print(f"âœ… å…¨é‡çŸ©é˜µæ„å»ºå®Œæˆ: {X_df.shape[0]} å­¦ç”Ÿ x {X_df.shape[1]} é¢˜ç›®")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    results = []

    # 2. éå† Q çŸ©é˜µ
    for q_name, q_path in Q_MATRIX_LIST.items():
        print(f"\nğŸ“‚ æ­£åœ¨è¯„æµ‹: [{q_name}]")
        print("-" * 50)
        
        # æ„å»º Q çŸ©é˜µ
        Q, valid_qs = build_smart_q_matrix(q_path, X_df.columns.astype(str).tolist(), MAX_KNOWLEDGE)
        if Q is None: continue
        
        X = X_df[valid_qs].values
        n_items = X.shape[1]
        n_kno = Q.shape[0]
        
        # 3. åˆ’åˆ†å­¦ç”Ÿ (Train / Test)
        # 80% çš„å­¦ç”Ÿç”¨äºè®­ç»ƒé¢˜ç›®å‚æ•°
        X_train_stu, X_test_stu = train_test_split(X, train_size=R_TRAIN_STUDENTS, random_state=RANDOM_SEED)
        
        # --- Phase 1: è®­ç»ƒ (Learning) ---
        print(f"   å…¨é‡è®­ç»ƒ (N={len(X_train_stu)})...")
        model = train_dina(X_train_stu, Q, max_iter=30)
        s_learned, g_learned, pi_learned = model['s'], model['g'], model['pi']
        A_all = model['A_all']
        
        # --- Phase 2: æµ‹è¯• (Split-Item Prediction) ---
        # å‡†å¤‡é®æŒ¡æ©ç 
        all_indices = np.arange(n_items)
        np.random.shuffle(all_indices)
        n_obs = int(n_items * K_OBSERVED_ITEMS)
        
        idx_obs = all_indices[:n_obs] # å·²çŸ¥é¢˜ç›®
        idx_tar = all_indices[n_obs:] # å¾…æµ‹é¢˜ç›®
        
        # å‡†å¤‡æ•°æ®
        X_obs = X_test_stu[:, idx_obs]
        X_tar = X_test_stu[:, idx_tar]
        
        Q_obs = Q[:, idx_obs]
        s_obs, g_obs = s_learned[idx_obs], g_learned[idx_obs]
        
        Q_tar = Q[:, idx_tar]
        s_tar, g_tar = s_learned[idx_tar], g_learned[idx_tar]
        
        # Step A: æ¨æ–­èƒ½åŠ›
        eta_obs = compute_eta(Q_obs, A_all)
        propa_obs = compute_propa(eta_obs, s_obs, g_obs)
        gamma_test = compute_gamma(X_obs, pi_learned, propa_obs)
        
        # Step B: é¢„æµ‹æœªçŸ¥é¢˜ç›®
        eta_tar = compute_eta(Q_tar, A_all)
        propa_tar = compute_propa(eta_tar, s_tar, g_tar)
        
        X_pred_prob = np.dot(gamma_test, propa_tar)
        X_pred_bin = (X_pred_prob >= 0.5).astype(int)
        
        # Step C: è¯„ä¼°
        acc = accuracy_score(X_tar.flatten(), X_pred_bin.flatten())
        loss = log_loss(X_tar.flatten(), X_pred_prob.flatten(), labels=[0,1])
        
        print(f"   [All Students] (K={n_kno}): Acc = {acc:.4f} | Loss = {loss:.4f} | (Test N={len(X_test_stu)})")
        
        results.append({
            "Matrix": q_name,
            "Knowledge_Dim": n_kno,
            "Test_Students": len(X_test_stu),
            "Split_Accuracy": acc,
            "Split_LogLoss": loss
        })

    # æ±‡æ€»è¾“å‡º
    print("\n" + "="*70)
    print("ğŸ† å…¨é‡æ•°æ®å®éªŒç»“æœæ±‡æ€» (æŒ‰ Accuracy æ’åº)")
    print("="*70)
    if results:
        res_df = pd.DataFrame(results)
        res_df = res_df[["Matrix", "Knowledge_Dim", "Split_Accuracy", "Split_LogLoss"]]
        print(res_df.sort_values(by="Split_Accuracy", ascending=False).to_string(index=False))
        res_df.to_csv("all_students_experiment_results.csv", index=False)
    else:
        print("æ— æœ‰æ•ˆç»“æœ")

if __name__ == "__main__":
    run_experiment()